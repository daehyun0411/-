{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_source = \"https://stats.idre.ucla.edu/stat/data/binary.csv\"\n",
    "df = pd.read_csv(data_source)\n",
    "\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0]], dtype=int64),\n",
       " array([[380.  ,   3.61,   3.  ],\n",
       "        [660.  ,   3.67,   3.  ],\n",
       "        [800.  ,   4.  ,   1.  ],\n",
       "        [640.  ,   3.19,   4.  ],\n",
       "        [520.  ,   2.93,   4.  ]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = df[\"admit\"].values.reshape(-1,1)\n",
    "x_data = df.iloc[:,1:].values\n",
    "\n",
    "y_data[:5], x_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27586207, 0.77586207, 0.66666667],\n",
       "       [0.75862069, 0.81034483, 0.66666667],\n",
       "       [1.        , 1.        , 0.        ],\n",
       "       [0.72413793, 0.53448276, 1.        ],\n",
       "       [0.51724138, 0.38505747, 1.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing # Min-Max Standardzation\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_data = min_max_scaler.fit_transform(x_data)\n",
    "\n",
    "x_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.705"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model, datasets\n",
    "\n",
    "logreg = linear_model.LogisticRegression(fit_intercept=True)\n",
    "logreg.fit(x_data, y_data.ravel())\n",
    "\n",
    "sum(logreg.predict(x_data) == y_data.ravel()) / len(y_data.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.50619015,  1.06983642,  1.11573376, -1.47695382])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.append(logreg.intercept_, logreg.coef_.ravel())\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_file_name = \"theta_bin.npy\"\n",
    "np.save(theta_file_name, theta)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.50619015,  1.06983642,  1.11573376, -1.47695382])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(theta_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[220.  ,   2.26,   1.  ],\n",
       "       [800.  ,   4.  ,   4.  ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max = np.vstack( (df.iloc[:,1:].values.min(axis=0), df.iloc[:,1:].values.max(axis=0)) )\n",
    "min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_file_name = \"min_max.npy\"\n",
    "np.save(min_max_file_name, min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[220.  ,   2.26,   1.  ],\n",
       "       [800.  ,   4.  ,   4.  ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(min_max_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.50619015,  1.06983642,  1.11573376, -1.47695382])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(theta_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f = open('logicmodel.pkl', 'wb')\n",
    "f.seek(0)\n",
    "\n",
    "pickle.dump(logreg,f )\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr = open('./logicmodel.pkl', 'rb')\n",
    "logreg_pickle = pickle.load(fr)\n",
    "\n",
    "sum(logreg.predict(x_data) == logreg_pickle.predict(x_data)) / len(y_data.ravel())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic_service_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb  8 16:16:31 2021 Server Starts - localhost:9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [08/Feb/2021 16:19:39] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Feb/2021 16:19:39] \"GET /favicon.ico HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from http.server import BaseHTTPRequestHandler, HTTPServer\n",
    "import time\n",
    "import cgi\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "hostName = \"localhost\"\n",
    "hostPort = 9000\n",
    "\n",
    "class StoreHandler(BaseHTTPRequestHandler):\n",
    "    def do_POST(self):\n",
    "\n",
    "        form = cgi.FieldStorage(\n",
    "            fp=self.rfile,\n",
    "            headers=self.headers,\n",
    "            environ={'REQUEST_METHOD':'POST',\n",
    "                     'CONTENT_TYPE':self.headers['Content-Type'],\n",
    "                     })\n",
    "        gre_score = float(form['gre'].value)\n",
    "        gpa_score = form['gpa'].value\n",
    "        rank_score = form['rank'].value\n",
    "\n",
    "        min_max_file = \"min_max.npy\"\n",
    "        theta_file = \"theta_bin.npy\"\n",
    "\n",
    "        theta = np.load(theta_file)\n",
    "        min_max = np.load(min_max_file)\n",
    "        x_data = np.array([gre_score,gpa_score, rank_score], dtype=np.float32)\n",
    "\n",
    "        x_data_rescale = (x_data - min_max[0]) / (min_max[1] - min_max[0])\n",
    "        x_data_rescale = np.insert(x_data_rescale, 0, 1)\n",
    "\n",
    "        def sigmoid(z):\n",
    "            return 1 / (1 + np.exp(z))\n",
    "\n",
    "        def hypothesis_function(x, theta):\n",
    "            z = (np.dot(-x, theta))\n",
    "            return sigmoid(z)\n",
    "\n",
    "        h_result = hypothesis_function(x_data_rescale, theta)\n",
    "        print(h_result)\n",
    "        print(theta)\n",
    "\n",
    "        result_set = h_result > 0.5\n",
    "\n",
    "        if result_set == True:\n",
    "            result = (\"Get Admission!!\")\n",
    "        else:\n",
    "            result = (\"Fail\")\n",
    "\n",
    "        self.respond(result.encode())\n",
    "\n",
    "    def do_GET(self):\n",
    "        response = b\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<body>\n",
    "    <p>Check your admission status!</p>\n",
    "    <form method=\"post\">\n",
    "        <p>gre: <input type=\"text\" name=\"gre\"></p>\n",
    "        <p>gpa: <input type=\"text\" name=\"gpa\"></p>\n",
    "        <p>rank: <input type=\"text\" name=\"rank\"></p>\n",
    "        <p><input type=\"submit\" value=\"submit\"></p>\n",
    "    </form>\n",
    "</body>\n",
    "</html>\n",
    "        \"\"\"\n",
    "\n",
    "        self.respond(response)\n",
    "\n",
    "    def respond(self, response, status=200):\n",
    "        self.send_response(status)\n",
    "        self.send_header(\"Content-type\", \"text/html\")\n",
    "        self.send_header(\"Content-length\", len(response))\n",
    "        self.end_headers()\n",
    "        self.wfile.write(response)\n",
    "\n",
    "\n",
    "myServer = HTTPServer((hostName, hostPort), StoreHandler)\n",
    "print(time.asctime(), \"Server Starts - %s:%s\"    % (hostName, hostPort))\n",
    "\n",
    "try:\n",
    "    myServer.serve_forever()\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "myServer.server_close()\n",
    "print(time.asctime(), \"Server Stops - %s:%s\" % (hostName, hostPort))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
